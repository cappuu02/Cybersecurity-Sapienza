In a Distributed System, each system has its own **logical clock**. If clocks are not aligned it is not possible to order events generated by different processes

**GOAL**: find a way to timestamp event that follows out intuitive notion of causality
## Causal Relationship
1. Due eventi avvenuti nello stesso processo $p_i$ sono avvenuti nello stesso ordine in cui $p_i$ li osserva.
![[Pasted image 20241009153239.png]]
2. quando $p_i$ invia un messaggio a $p_j$, l'evento di invio avviene prima dell'evento di ricezione:
![[Pasted image 20241009153254.png]]
**Lamport** ha introdotto la relazione happened-before che cattura le dipendenze causali tra gli eventi (**relazione d'ordine causale**):
- denotiamo con $→_i$ la relazione d'ordine tra gli eventi di un processo $p_i$.
- denotiamo con → la relazione happened-before tra una qualsiasi coppia di eventi.
## Happened-Before Relation:
Two event $e$ and $e'$ related by happened-before relation $(e\to e')$ if:
- **Local ordering**: $\exists p_i|e\to_i e'$ 
- **snd-rcv ordering**: $\forall m, send(m)\to recive(m)$
	- $e= send(m)$ is the event of sending a message $m$.
	- $e'=recive(m)$ is the event of receipt of the same message $m$
- **Transativity**: $\exists e'':(e\to e'') \wedge (e''\to e') \Rightarrow e\to e'$
	- the happened-before relation is transitive

![[Pasted image 20241009153544.png]]

Applying these three rules is possible to define a causal ordered sequence of events $e_1, e_2, … , e_n$.

**Notes**:
- la sequenza $e_1, e_2, ..., e_n$ **può non essere unica**.
- Può **esistere una coppia di eventi tale che $e_1$ e $e_2$ non sono in una relazione happened-before relation**.
- Se $e_4$ e $e_3$ non sono in runa relazione happened-before, allora sono **concurrent** ($e_4||e_3$).
- per ogni due eventi qualsiasi $e_x$ e $e_y$ nella storia dell'esecuzione di un sistema distribuito, o $e_x → e_y, e_y → e_x$ o $e_y|e_x$.

![[Pasted image 20241009154351.png|500]]

```ad-example

![[Pasted image 20241009154428.png]]$S_1 = <e^1_1,e_2^1,e_2^2,e^2_3,e^3_3,e^3_1,e^4_1,e^5_1,e^4_2>$
$S_2= <e^1_3,e^2_1,e^3_1,e^4_1,e^5_3>$
Concurrent Elements: $(e^1_3,e^1_2)$ because they are overlaped and they are not in an happened-before relationship.

> Tutti i restanti eventi sono in una happened-befor relationship
```

## Logical clock
Logical clock, introdotto da lamport, è un registro di conteggio software monotonicamente crescente (non legato all'orologio fisico). L'orologio logico non è correlato all'orologio fisico.

Each process $p_i$ employs its logical clock $L_i$ to apply a timestamp to events.
$L_i(e)$ is the **logical timestamp** assigned, using the logical clock, by a process $p_i$ to event $e$.

**Property**:
if $e\to e'$ then $L(e)<L(e')$
### Scalar Logical Clock
Each process $p_i$ initializes its logical clock $L_i=0$
- when $p_i$ sends a message $m$:
	- creates an event $send(m)$
	- increases $L_i$
	- timestamps $m$ with $t=L_i$
- when $p_i$ recives a message $m$ with timestamp $t$
	- updates its logical clock $L_i = max(t,L_i)$
	- produces an event $recive(m)$
	- increases $L_i$
![[Pasted image 20241009154853.png|500]]
because of the property (if $e\to e'$ then $L(e)<L(e')$)

![[Distributed System/Images/73.png]]
![[Distributed System/Images/74.png]]

```ad-example
![[Distributed System/Images/75.png]]

```

## Limits of Scalar Logical Clock
Gli orologi logici scalari possono garantire la proprietà
- se $e$ $\to$ $e'$ allora $L(e) <L(e')$

Ma non è **possibile garantire**:
- se $L(e)<L(e')$ allora $e \to e'$ (non è sempre vero perch).

Se il timestamp di un evento è più piccolo di quello di un altro ($L(e) < L(e')$), non significa necessariamente che $e$ ha causato $e'$. Potrebbero essere eventi indipendenti o "concurrent" (cioè accaduti nello stesso periodo senza influenzarsi a vicenda).

## Vector clock - Capture Casuality
**GOAL**: capture causality (if $L(e) <L(e')$ then $e\to e'$)

$L(e)$ has not to be a single number. what if $L(e)$ is a history of events that happened before $e$ (including $e$)?

![[Pasted image 20241009155456.png]]
$$L(e_i)>L(e_j)\Leftrightarrow \forall k:L(e_j)_{History_k}\subseteq L(e_i)_{History_k}\wedge \exists x:L(e_j)_{History_x}\subset L(e_i)_{History_x}$$

(there is a causal path form $e\to e'$ and the structure that contains $e$ is less than the structure that contains $e'$)
![[Pasted image 20241009155842.png]]
$History_x\subset History'_x \to History_x$ is a proper prefix of $History'_x$
We can say that: $$History_x \subset History_x' \to len(History_x)<len(History'_x)$$![[Pasted image 20241009160200.png|500]]
>An event $e$ is in happened-before relation with an event $e'$ if in his $History$ there is a tuple of elements of $e$ that $\subseteq$ with the tuple of $e'$

>A vector clock for a set of N processes is an array of N integer counters:
- Ciascun processo $p_i$ mantiene un orologio vettoriale $V_i$ e mediante esso registra gli eventi.
- Analogamente all'orologio scalare, al messaggio $m$ è allegato un orologio vettoriale (in questo caso alleghiamo un array di numeri interi).

Scalar Clock: $e \to e' \Rightarrow L(e) < L(e')$
Vector Clock: $e \to e' \Leftrightarrow V(e) < V(e')$


==Implementation==:
- each process $p_i$ **initializes its clock** $V_i= 0$
- $p_i$ **increases** $V_i[i]+1$ **when it generates a new event** $e$.
- when $p_i$ **sends a message** $m$ then:
	- creates an event $send(m)$.
	- $V_i[i]+1$.
	- timestamps $m$ with $t=V_i$.
- when $p_i$ **recives a message** $m$ containing timestamp $V-t$ then:
	- updates its logical clock: $V_i[j]= max(V_t[j],V_i[j]) \hspace{10px} \forall j \in \{1,...,N\}$.
	- generates an event $recive(m)$.
	- increases $V_i$.

where:
- $V_i[i]$ represents the number of events produced by $p_i$.
- $V_i[j]$ with $i\ne j$ represents the number of events genereted by $p_j$ that $p_i$ knows.

**Properties**:
- $V = V' \Leftrightarrow V[j] = V'[j] \hspace{10px} \forall j \in \{1,..,N\}$
- $V\le V' \Leftrightarrow V[j]\le V'[j] \hspace{10px} \forall j \in \{1,..,N\}$
- $V<V' \Leftrightarrow V\le V' \wedge\hspace{5px} \exists \hspace{5px}j \in \{1,...,N\} |V[j]<V'[j]$

```ad-example
title: Example 1
![[Pasted image 20241009161634.png|250]]

```

```ad-example
![[Pasted image 20241009161721.png]]


```

$[-,-,1]<[4,3,2]\Rightarrow e^1_3\to e^4_1$
$[4,3,2]?[3,-,3]\Rightarrow e^4_1||e^3_3$

**Each mechanism can be used to solve different problems**:
- Scalar Timestamp → Lamport’s Mutual Exclusion
- Vector Timestamp → Causal Broadcast

## Mutual exclusion abstraction - no crash tollerant

**Events**:
- **Request**: from upper layer - **requests** **access to Critical Section** (CS).
- **Grant**: to upper layer - **grant the access to CS**.
- **Release**: from upper layer - **release the CS**.
**Properties**:
- (**Mutual Exclusions**) at any time $t$, only one process is inside the CS.
- (**Liveness**) if a process $p$ requests access, then it eventually enters the CS.
- (**Fairness**) if the request of process $p$ happens before the request of process $q$, then $q$ cannot access the CS before $p$.
![[Pasted image 20241009162208.png|250]]

The algorithm assumes **no crashes** ($F=0$):
when a process wants to enter the CS (critical section) it sends a request message to all the other (using **scalar clocks**). The algorithm assume a FIFO link.

## Lamport's Algorithm

>![[Pasted image 20241009162616.png]]

 Per ogni processo $p_i$:
 - **ck**: un contatore del clock scalare locale del processo
 - **Requests**: insieme di richieste che tiene traccia dei processi che vogliono accedere alla sezione critica.

==**Funzionamento Algoritmo**==
1. **Accesso alla sezione critica**
	Quando un processo $p_i$ vuole accedere alla CS incrementa il proprio scalarclock di 1, invia un messaggio di richiesta REQ a tutti gli altri processi, includendo il proprio ID e il timestamp (scalarclock) ed infine aggiunge la propria richiesta all'insieme Requests.
2. **Ricezione di una richiesta**
	Quando un processo $p_j$ riceve un messaggio di richiesta da $p_i$ aggiunge tale richiesta al proprio insieme di Requestes e poi, risponde a $p_i$ con un messaggio di conferma ACK, includendo il proprio timestamp.
3. **Rilascio della sezione critica**
	Quando $p_i$ ha terminato di utilizzare la sezione critica:
	- Incrementa il clock scalare di 1
	- Invia un messaggio di rilascio RLS a tutti gli altri processi
	- Rimuove la propria richiesta da Requests
4. **Condizioni per accedere alla sezione critica**
	Un processo puo accedere alla sezione critica se la propria richiesta ha il timestamp piu basso tra tutte quelle presenti in Requests. Ha ricevuto ACK da tutti gli altri processi.

Le richieste dunque vengono ordinate considerando:
- Il valore del timestamp (scalarclock)
- in caso di timestamp uguali, l'ID del processo

```ad-success
title: Vantaggi
- Assicurare mutua esclusione senza deadlock (accesso di un solo $p$ alla CS)
- Funziona in ambiente distribuito

```

![[Distributed System/Images/43.png]]
![[Distributed System/Images/44.png]]
![[Distributed System/Images/45.png]]
![[Distributed System/Images/46.png]]
![[Distributed System/Images/47.png]]
![[Distributed System/Images/48.png]]
### Dimonstration

==**Mutua esclusione**==
Supponiamo per assurdo che due processi $p_1$ e $p_2$ entrino contemporaneamente nella Sezione Critica (CS). L'algoritmo garantisce che questo non possa avvenire per i seguenti motivi:

1. *Ogni processo deve ricevere gli ACK* da tutti gli altri prima di accedere alla CS.  
   - Quando $p_1$ riceve un ACK da $p_2$, vuol dire che $p_2$ ha già inserito la richiesta di $p_1$ nel proprio insieme di richieste $Requests$, poiché inviare un ACK implica aver registrato la richiesta.
   - Analogamente, quando $p_2$ riceve un ACK da $p_1$, $p_1$ ha già registrato la richiesta di $p_2$ nel proprio insieme di richieste.

2. Le richieste sono ordinate in base al *timestamp scalare*: 
   - Supponiamo che $ts(req_{p_1})$ (il timestamp della richiesta di $p_1$) sia minore di $ts(req_{p_2})$. 
   - Questo implica che la richiesta di $p_1$ ha priorità e deve essere soddisfatta prima di quella di $p_2$.  
   - Se entrambe le richieste vengono accettate contemporaneamente, violerebbe questa regola di ordinamento, generando una contraddizione.

3. *FIFO garantisce l'ordine*:
   - Poiché i messaggi viaggiano in FIFO, quando $p_j$ riceve una richiesta di $p_i$, la registra prima di inviare il proprio ACK.
   - Dato che le richieste sono totalmente ordinate in $Requests$, non è possibile che due processi entrino nella CS simultaneamente.

>*Conclusione:* Solo un processo alla volta può entrare nella CS.



==**Equità**==
L'algoritmo garantisce che le richieste vengano soddisfatte in ordine temporale corretto, rispettando la relazione *happened-before*.  

1. Supponiamo che $p_i$ e $p_j$ abbiano entrambe inviato richieste di accesso alla CS.
2. Se il timestamp della richiesta di $p_i$ è minore di quello di $p_j$, allora:
   - Tutti i processi vedranno $req_{p_i}$ prima di $req_{p_j}$.
   - Questo accade perché i messaggi vengono ricevuti in ordine FIFO.
3. Di conseguenza, $p_i$ entrerà nella CS prima di $p_j$, rispettando l'ordine temporale.

>*Conclusione:* Le richieste vengono gestite in ordine di timestamp, garantendo equità.


==**Numero di operazioni per un'esecuzione nella CS**==
- *Richieste:* $N - 1$ messaggi $REQ$.
- *ACK:* $N - 1$ messaggi.
- *Rilascio:* $N - 1$ messaggi $RLS$.

*Totale:* $3(N - 1)$ operazioni.


==**Ritardo per accedere alla CS**==
Il ritardo per un processo che entra nella CS è compreso tra:
- *$\Omega(2)$*: Il minimo ritardo è dato da 2 passi (invio e ricezione di un messaggio).
- *$O(N + 2)$*: Il massimo ritardo dipende dal numero totale di processi ($N$) e dai messaggi richiesti
